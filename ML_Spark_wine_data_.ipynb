{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suman Kumar Sahu\n",
    "\n",
    "Objective:\n",
    "Dataset:\n",
    "\n",
    "Status:\n",
    "\n",
    "Highlevel Abstraction: Estimators and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame->Transformer(conversion of dataframes)->Estimator(ML algos are all estimators). An algo that fit on dataframe to produce Tranformer (change dataframes)...\n",
    "\n",
    "Pipeline: Chains of estimators and transformers to form a machine learning workflow\n",
    "Chains a series of operations to be performed on DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Spark ML Libraries\n",
    "\n",
    "which means no sc but SparkSession which encapsulates spark context sql context and all other context available with spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sp=SparkSession\\\n",
    ".builder\\\n",
    ".appName('Predicting the grape variety from wine characteristic')\\\n",
    ".getOrCreate()\n",
    "\n",
    "rawData=spark.read\\\n",
    ".format('csv')\\\n",
    ".option('header','false')\\\n",
    ".load(\"/home/titan/dataset/ML_JRVI/wine.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=rawData.toDF('Label',\n",
    "                    'Alcohol',\n",
    "                    'MalicAcid',\n",
    "                    'Ash',\n",
    "                    'AshAlkalinity',\n",
    "                    'Magnesium',\n",
    "                    'TotalPhenols',\n",
    "                    'Flavanoids',\n",
    "                    'NonFlavanoidPhenols',\n",
    "                    'Proanthocyanins',\n",
    "                    'ColorIntensity',\n",
    "                    'Hue',\n",
    "                    'OD',\n",
    "                    'Proline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Label: string, Alcohol: string, MalicAcid: string, Ash: string, AshAlkalinity: string, Magnesium: string, TotalPhenols: string, Flavanoids: string, NonFlavanoidPhenols: string, Proanthocyanins: string, ColorIntensity: string, Hue: string, OD: string, Proline: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Label='1', Alcohol='14.23', MalicAcid='1.71', Ash='2.43', AshAlkalinity='15.6', Magnesium='127', TotalPhenols='2.8', Flavanoids='3.06', NonFlavanoidPhenols='.28', Proanthocyanins='2.29', ColorIntensity='5.64', Hue='1.04', OD='3.92', Proline='1065'),\n",
       " Row(Label='1', Alcohol='13.2', MalicAcid='1.78', Ash='2.14', AshAlkalinity='11.2', Magnesium='100', TotalPhenols='2.65', Flavanoids='2.76', NonFlavanoidPhenols='.26', Proanthocyanins='1.28', ColorIntensity='4.38', Hue='1.05', OD='3.4', Proline='1050'),\n",
       " Row(Label='1', Alcohol='13.16', MalicAcid='2.36', Ash='2.67', AshAlkalinity='18.6', Magnesium='101', TotalPhenols='2.8', Flavanoids='3.24', NonFlavanoidPhenols='.3', Proanthocyanins='2.81', ColorIntensity='5.68', Hue='1.03', OD='3.17', Proline='1185')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+----+-------------+---------+------------+----------+-------------------+---------------+--------------+----+----+-------+\n",
      "|Label|Alcohol|MalicAcid| Ash|AshAlkalinity|Magnesium|TotalPhenols|Flavanoids|NonFlavanoidPhenols|Proanthocyanins|ColorIntensity| Hue|  OD|Proline|\n",
      "+-----+-------+---------+----+-------------+---------+------------+----------+-------------------+---------------+--------------+----+----+-------+\n",
      "|    1|  14.23|     1.71|2.43|         15.6|      127|         2.8|      3.06|                .28|           2.29|          5.64|1.04|3.92|   1065|\n",
      "|    1|   13.2|     1.78|2.14|         11.2|      100|        2.65|      2.76|                .26|           1.28|          4.38|1.05| 3.4|   1050|\n",
      "|    1|  13.16|     2.36|2.67|         18.6|      101|         2.8|      3.24|                 .3|           2.81|          5.68|1.03|3.17|   1185|\n",
      "|    1|  14.37|     1.95| 2.5|         16.8|      113|        3.85|      3.49|                .24|           2.18|           7.8| .86|3.45|   1480|\n",
      "|    1|  13.24|     2.59|2.87|           21|      118|         2.8|      2.69|                .39|           1.82|          4.32|1.04|2.93|    735|\n",
      "+-----+-------+---------+----+-------------+---------+------------+----------+-------------------+---------------+--------------+----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "def vectorize(data):\n",
    "    return data.rdd.map(lambda x: [x[0],Vectors.dense(x[1:])]).toDF(['label','features'])\n",
    "#note the mention of '.rdd' logically incoherent\n",
    "#dense vector opposite of spars vector... sparse representation vs dense representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorisedData=vectorize(dataset)\n",
    "type(vectorisedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[14.23,1.71,2.43,...|\n",
      "|    1|[13.2,1.78,2.14,1...|\n",
      "|    1|[13.16,2.36,2.67,...|\n",
      "|    1|[14.37,1.95,2.5,1...|\n",
      "|    1|[13.24,2.59,2.87,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorisedData.take(5)\n",
    "vectorisedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting categorical data to \n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "labelIndexer=StringIndexer (inputCol='label',\n",
    "outputCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='1', features=DenseVector([14.23, 1.71, 2.43, 15.6, 127.0, 2.8, 3.06, 0.28, 2.29, 5.64, 1.04, 3.92, 1065.0]), indexedLabel=1.0),\n",
       " Row(label='1', features=DenseVector([13.2, 1.78, 2.14, 11.2, 100.0, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.4, 1050.0]), indexedLabel=1.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexedData=labelIndexer.fit(vectorisedData).transform(vectorisedData)\n",
    "indexedData.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: string, features: vector, indexedLabel: double]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    3|\n",
      "|    1|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedData.select('label').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|indexedLabel|\n",
      "+------------+\n",
      "|         0.0|\n",
      "|         1.0|\n",
      "|         2.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedData.select('indexedLabel').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData,testData)=indexedData.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree= DecisionTreeClassifier(labelCol='indexedLabel',\n",
    "                                   featuresCol='features',\n",
    "                                   impurity='gini',\n",
    "                                   maxDepth=3,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=dtree.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator=MulticlassClassificationEvaluator(labelCol='indexedLabel',\n",
    "                                           predictionCol='prediction',\n",
    "                                           metricName='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------+--------------------+----------+\n",
      "|label|            features|indexedLabel| rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------------+--------------+--------------------+----------+\n",
      "|    1|[12.85,1.6,2.52,1...|         1.0| [2.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|    1|[12.93,3.8,2.65,1...|         1.0| [2.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|    1|[13.05,1.65,2.55,...|         1.0|[0.0,47.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.2,1.78,2.14,1...|         1.0|[0.0,47.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.24,2.59,2.87,...|         1.0|[47.0,1.0,0.0]|[0.97916666666666...|       0.0|\n",
      "+-----+--------------------+------------+--------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data=model1.transform(testData)\n",
    "transformed_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 accuracy: 0.8379691653375865\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.getMetricName(),'accuracy:',\n",
    "      evaluator.evaluate(transformed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
